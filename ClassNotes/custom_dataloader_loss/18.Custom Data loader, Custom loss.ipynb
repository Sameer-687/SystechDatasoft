{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad21252d",
   "metadata": {},
   "source": [
    "# Custom dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e8ae6d",
   "metadata": {},
   "source": [
    "### Custom DataLoader Example\n",
    "\n",
    "Illustration of how we can efficiently iterate through custom (image) datasets. For this, suppose \n",
    "- mnist_train, mnist_valid, and mnist_test are image folders you created with your own custom images\n",
    "- mnist_train.csv, mnist_valid.csv, and mnist_test.csv are tables that store the image names with their associated class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d74567b",
   "metadata": {},
   "source": [
    "# 1) Inspecting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f79c90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af90d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('data/mnist/mnist_train/1.png')\n",
    "plt.imshow(im, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4ad706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "im_array = np.array(im)\n",
    "print('Array Dimensions', im_array.shape)\n",
    "print()\n",
    "print(im_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06183f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6999a9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/mnist/mnist_train.csv')\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a48fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/mnist/mnist_test.csv')\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d965ea",
   "metadata": {},
   "source": [
    "# 2) Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecb27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "    \n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.img_names = df['File Name']\n",
    "        self.y = df['Class Label']\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.img_dir,\n",
    "                                      self.img_names[index]))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = self.y[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc78a40e",
   "metadata": {},
   "source": [
    "# 3) Custom Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df45ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# Note that transforms.ToTensor()\n",
    "# already divides pixels by 255. internally\n",
    "\n",
    "custom_transform = transforms.Compose([#transforms.Lambda(lambda x: x/255.), # not necessary\n",
    "                                       transforms.ToTensor()\n",
    "                                      ])\n",
    "\n",
    "train_dataset = MyDataset(csv_path='data/mnist/mnist_train.csv',\n",
    "                          img_dir='data/mnist/mnist_train',\n",
    "                          transform=custom_transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=32,\n",
    "                          drop_last=True,\n",
    "                          shuffle=True, # want to shuffle the dataset\n",
    "                          num_workers=0) # number processes/CPUs to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f71007",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = MyDataset(csv_path='data/mnist/mnist_valid.csv',\n",
    "                          img_dir='data/mnist/mnist_valid',\n",
    "                          transform=custom_transform)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=100,\n",
    "                          shuffle=False,\n",
    "                          num_workers=0)\n",
    "\n",
    "\n",
    "\n",
    "test_dataset = MyDataset(csv_path='data/mnist/mnist_test.csv',\n",
    "                         img_dir='data/mnist/mnist_test',\n",
    "                         transform=custom_transform)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=100,\n",
    "                         shuffle=False,\n",
    "                         num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0687a77b",
   "metadata": {},
   "source": [
    "## 4) Iterating Through the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e60a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)\n",
    "\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffd4ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c956ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image_as_vector = x.view(-1, 28*28)\n",
    "print(x_image_as_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d61dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01ce2c6",
   "metadata": {},
   "source": [
    "# Now let's train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd6afb2",
   "metadata": {},
   "source": [
    "#### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ea644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04af2507",
   "metadata": {},
   "source": [
    "#### Define Custom Dataset Class\n",
    "This class is for creating a custom dataset. It is a subclass of torch.utils.data.Dataset. It requires a directory with images and transformations. It has two main methods: __len__ returns the number of samples in the dataset, and __getitem__ loads and returns an image and its corresponding label.\n",
    "\n",
    "### Dataset Structure\n",
    "\n",
    "For the `mnist` custom class to work properly, the dataset should be structured in a specific way. Below is the expected directory structure:\n",
    "\n",
    "```\n",
    "dataset_directory/\n",
    "├── mnist_train/\n",
    "│   ├── 0.jpg\n",
    "│   ├── 1.jpg\n",
    "│   └── ...\n",
    "└── mnist_test/\n",
    "    ├── 100.jpg\n",
    "    ├── 200.jpg\n",
    "    └── ...\n",
    "    mnist_val/\n",
    "    ├── 288.jpg\n",
    "    ├── 999.jpg\n",
    "    └── ...\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1e47a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "    \n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.img_names = df['File Name']\n",
    "        self.y = df['Class Label']\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.img_dir,\n",
    "                                      self.img_names[index]))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = self.y[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a26143",
   "metadata": {},
   "source": [
    "### Initialization Method\n",
    "\n",
    "In the `__init__` method, when an instance of the class is created, it expects:\n",
    "\n",
    "- `img_dir`: The path to the directory where images are stored.\n",
    "- `transform`: Any transformations to apply to the images.\n",
    "\n",
    "- `self.img_dir` stores the main directory where images are located.\n",
    "- `self.transform` stores the transformations to be applied to each image.\n",
    "- `self.img_names` stores all the file name csv file.\n",
    "- `self.y` stores all the class label from csv file.\n",
    "\n",
    "### Length Method\n",
    "\n",
    "The `__len__` method is required by PyTorch. It returns the total number of samples in the dataset.\n",
    "\n",
    "\n",
    "### Get Item Method\n",
    "\n",
    "The `__getitem__` method is used to retrieve a single item from the dataset given an index `idx`. \n",
    "- `self.transform is not None`: If it is set to none then no transformation will be applied.\n",
    "\n",
    "\n",
    "- Finally, it returns the transformed image and its label as a tuple.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71654da",
   "metadata": {},
   "source": [
    "#### Define CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd648d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Architecture\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=64 * 7 * 7, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        print(x.shape)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0de5ec6",
   "metadata": {},
   "source": [
    "#### Initialize Dataset and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6d9456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# Note that transforms.ToTensor()\n",
    "# already divides pixels by 255. internally\n",
    "\n",
    "custom_transform = transforms.Compose([#transforms.Lambda(lambda x: x/255.), # not necessary\n",
    "                                       transforms.ToTensor()\n",
    "                                      ])\n",
    "\n",
    "train_dataset = MyDataset(csv_path='data/mnist/mnist_train.csv',\n",
    "                          img_dir='data/mnist/mnist_train',\n",
    "                          transform=custom_transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=32,\n",
    "                          drop_last=True,\n",
    "                          shuffle=True, # want to shuffle the dataset\n",
    "                          num_workers=0) # number processes/CPUs to use\n",
    "valid_dataset = MyDataset(csv_path='data/mnist/mnist_valid.csv',\n",
    "                          img_dir='data/mnist/mnist_valid',\n",
    "                          transform=custom_transform)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=100,\n",
    "                          shuffle=False,\n",
    "                          num_workers=0)\n",
    "\n",
    "\n",
    "\n",
    "test_dataset = MyDataset(csv_path='data/mnist/mnist_test.csv',\n",
    "                         img_dir='data/mnist/mnist_test',\n",
    "                         transform=custom_transform)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=100,\n",
    "                         shuffle=False,\n",
    "                         num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd505705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Architecture\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=64 * 7 * 7, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        print(x.shape)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f6d5c5",
   "metadata": {},
   "source": [
    "#### Initialize the Model, Loss Function, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d680122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2698ec96",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630be9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}'):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    print(f'Training Loss: {running_loss/len(train_loader)}, Training Accuracy: {train_accuracy}%')\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(valid_loader, desc='Validation'):\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    print(f'Validation Accuracy: {val_accuracy}%')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e5b62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Plotting the training loss\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss', color='blue')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training Loss')\n",
    "\n",
    "# Plotting the training accuracy\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(train_accuracies, label='Training Accuracy', color='green')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.title('Training Accuracy')\n",
    "\n",
    "# Plotting the validation accuracy\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(val_accuracies, label='Validation Accuracy', color='orange')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.title('Validation Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc19bc2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7523d1eb",
   "metadata": {},
   "source": [
    "### Custom Loss:\n",
    "Why do we need custom loss function?\n",
    "\n",
    "In PyTorch, a custom loss function can be useful in several scenarios:\n",
    "\n",
    "   * **Non-standard loss:** Sometimes, the standard loss functions provided by PyTorch may not be suitable for your specific task or problem. In such cases, you can define a custom loss function that incorporates the specific requirements of your task.\n",
    "\n",
    "   * **Domain-specific loss:** If you are working on a problem in a specific domain, you may have domain-specific knowledge that can be leveraged to design a more effective loss function. For example, in computer vision tasks, you may want to penalize certain types of errors more heavily based on their importance in the domain.\n",
    "\n",
    "   * **Multi-objective optimization:** In some cases, you may have multiple objectives to optimize simultaneously. In such situations, you can define a custom loss function that combines multiple objectives into a single loss value. This allows you to guide the training process by balancing the importance of different objectives.\n",
    "\n",
    "   * **Advanced loss computations:** Custom loss functions provide flexibility in implementing complex loss computations that involve additional operations or metrics beyond simple element-wise comparisons. This can include calculations involving attention mechanisms, label smoothing, or other advanced techniques.\n",
    "\n",
    "   * **Research and experimentation:** When developing new models or exploring innovative approaches, you may need to design novel loss functions to match your proposed architectures or algorithms. Custom loss functions enable you to experiment and evaluate your ideas effectively.\n",
    "\n",
    "By creating a custom loss function in PyTorch, you have the freedom to tailor the loss calculation according to your specific requirements, allowing you to optimize your models more effectively for the task at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce54ef95",
   "metadata": {},
   "source": [
    "### Pytorch Custom Loss function implementation\n",
    "\n",
    "#### To write a custom loss class in PyTorch, you need to create a subclass of the torch.nn.Module class and implement the forward method. The forward method takes the model's predicted output and the target values as input and computes the loss.\n",
    "\n",
    "Here's an explanation and implementation of a custom loss class using a CNN on the MNIST dataset in PyTorch:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343afeca",
   "metadata": {},
   "source": [
    "#### Importing Required Libraries\n",
    "This block imports the necessary libraries for the code, including PyTorch modules (torch, nn, optim), torchvision, transforms for data preprocessing, torch.nn.functional (F), matplotlib for visualization, and tqdm for the progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585f354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df2994c",
   "metadata": {},
   "source": [
    "#### Define Custom Loss Class\n",
    "This block defines a custom loss class CustomCrossEntropyLoss. The class inherits from nn.Module. In the forward method, it takes predictions and targets as input and computes the mean squared error between them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183ddd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, weight=None, reduction='mean'):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, predicted, target):\n",
    "        # Compute the log softmax of the input\n",
    "        log_softmax_input = torch.log_softmax(predicted, dim=1)\n",
    "        \n",
    "        # Calculate the negative log probabilities of the true classes\n",
    "        neg_log_probabilities = -log_softmax_input[range(len(target)), target]\n",
    "        \n",
    "        # You can apply additional custom modifications to the log probabilities if needed\n",
    "        \n",
    "        # Calculate the mean loss (or other reduction if specified)\n",
    "        loss = neg_log_probabilities.mean()\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9250260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Architecture\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=64 * 7 * 7, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef58957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformation\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Split the training dataset into training and validation sets\n",
    "# You can adjust the split ratio as needed\n",
    "total_train_samples = len(train_dataset)\n",
    "train_ratio = 0.8  # 80% for training\n",
    "train_size = int(train_ratio * total_train_samples)\n",
    "val_size = total_train_samples - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders for training, validation, and testing\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Checking dataset sizes\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Testing dataset size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d740ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Loss Function and Optimizer\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = CustomCrossEntropyLoss() # Using CrossEntropyLoss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188976d7",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c94cfca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}'):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    print(f'Training Loss: {running_loss/len(train_loader)}, Training Accuracy: {train_accuracy}%')\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    running_val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc='Validation'):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = running_val_loss / len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd891d67",
   "metadata": {},
   "source": [
    "## Ensemble Loss\n",
    "\n",
    "Ensemble loss is a technique used in machine learning to combine the predictions of multiple models, called an ensemble, to improve the overall performance and robustness. Instead of relying on a single model's predictions, an ensemble of models aggregates their outputs to make a final decision. This approach can often lead to better generalization and more accurate predictions, especially when individual models have different strengths and weaknesses.\n",
    "\n",
    "### Applications and Benefits\n",
    "\n",
    "1. **Improved Performance**: Ensemble methods can enhance the predictive accuracy of models, as the ensemble's combined decision tends to be more reliable and less prone to overfitting.\n",
    "\n",
    "2. **Robustness**: Ensembles can handle noisy or uncertain data more effectively than individual models, as errors in one model are often balanced out by other models.\n",
    "\n",
    "3. **Model Diversity**: Ensemble techniques work best when the individual models are diverse, meaning they have different architectures or are trained on different subsets of data. This diversity helps capture different patterns in the data.\n",
    "\n",
    "4. **Reduced Risk**: By combining multiple models, the risk of relying on a single faulty or poorly trained model is mitigated, making the overall prediction more trustworthy.\n",
    "\n",
    "5. **Ensemble Learning**: Ensemble techniques, like bagging, boosting, and stacking, are widely used in machine learning competitions and real-world applications to achieve state-of-the-art results.\n",
    "\n",
    "### Code with Ensemble Loss (Mean Absolute Error and Mean Squared Error)\n",
    "\n",
    "Below is the code for training a CNN model on the CIFAR-10 dataset using ensemble loss. The ensemble loss in this case will be a combination of Mean Absolute Error (MAE) and Mean Squared Error (MSE).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b811cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the ensemble loss combining MAE and MSE\n",
    "class EnsembleLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, reduction='mean'):\n",
    "        super(EnsembleLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.mae_loss = nn.L1Loss(reduction=reduction)\n",
    "        self.mse_loss = nn.MSELoss(reduction=reduction)\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        # Ensure both output and target tensors have the same shape (batch size)\n",
    "        assert output.shape[0] == target.shape[0], \"Output and target batch sizes must match.\"\n",
    "        print(output.shape)\n",
    "        mae_loss = self.mae_loss(output, target)\n",
    "        mse_loss = self.mse_loss(output, target)\n",
    "        ensemble_loss = self.alpha * mae_loss + (1 - self.alpha) * mse_loss\n",
    "        return ensemble_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5110eab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 16 * 16, 120)  # Adjust the input size based on the image dimensions\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)  # Output size matches the number of classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = out.view(-1, 16 * 16 * 16)  # Flatten before fully connected layers\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "# Define the EnsembleLoss class combining MAE and MSE\n",
    "class EnsembleLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super(EnsembleLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.mae_loss = nn.L1Loss()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        mae_loss = self.mae_loss(output, target)\n",
    "        mse_loss = self.mse_loss(output, target)\n",
    "        ensemble_loss = self.alpha * mae_loss + (1 - self.alpha) * mse_loss\n",
    "        return ensemble_loss\n",
    "\n",
    "# Set the device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set the hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Load and preprocess the CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create an instance of the CNN model and move it to the device\n",
    "num_classes = 10  # Number of classes in CIFAR-10\n",
    "cnn = CNN(num_classes=num_classes).to(device)\n",
    "\n",
    "# Define the ensemble loss function and optimizer\n",
    "ensemble_criterion = EnsembleLoss(alpha=0.7)\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = cnn(images)\n",
    "        loss = ensemble_criterion(outputs, nn.functional.one_hot(labels, num_classes=num_classes).float())\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            # Calculate training accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            accuracy = correct / labels.size(0)\n",
    "            accuracy_list.append(accuracy)\n",
    "            # Track the loss\n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{total_step}], Loss: {loss.item()}, Accuracy: {accuracy}\")\n",
    "\n",
    "# Testing\n",
    "cnn.eval()  # Switch to evaluation mode\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = cnn(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = correct / total\n",
    "    print(f\"Accuracy on the test set: {test_accuracy}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loss_list, label='Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(accuracy_list, label='Accuracy', color='orange')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66797c5b",
   "metadata": {},
   "source": [
    "# Comparison: Ensemble loss vs MSE vs MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd714adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 16 * 16, 120)  # Adjust the input size based on the image dimensions\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)  # Output size matches the number of classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = out.view(-1, 16 * 16 * 16)  # Flatten before fully connected layers\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "# Define the EnsembleLoss class combining MAE and MSE\n",
    "class EnsembleLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super(EnsembleLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.mae_loss = nn.L1Loss()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        mae_loss = self.mae_loss(output, target)\n",
    "        mse_loss = self.mse_loss(output, target)\n",
    "        ensemble_loss = self.alpha * mae_loss + (1 - self.alpha) * mse_loss\n",
    "        return ensemble_loss\n",
    "\n",
    "# Define the individual loss functions\n",
    "class MAELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MAELoss, self).__init__()\n",
    "        self.loss = nn.L1Loss()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        return self.loss(output, target)\n",
    "\n",
    "class MSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MSELoss, self).__init__()\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        return self.loss(output, target)\n",
    "\n",
    "# Set the device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set the hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Load and preprocess the CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create an instance of the CNN model and move it to the device\n",
    "num_classes = 10  # Number of classes in CIFAR-10\n",
    "cnn = CNN(num_classes=num_classes).to(device)\n",
    "\n",
    "# Define the ensemble loss function and optimizer\n",
    "ensemble_criterion = EnsembleLoss(alpha=0.7)\n",
    "mae_criterion = MAELoss()\n",
    "mse_criterion = MSELoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define loss function names in a list\n",
    "loss_function_names = [\"Ensemble Loss\", \"MSE Loss\", \"MAE Loss\"]\n",
    "\n",
    "# Training loop\n",
    "total_step = len(train_loader)\n",
    "loss_lists = [[] for _ in range(len(loss_function_names))]\n",
    "accuracy_lists = [[] for _ in range(len(loss_function_names))]\n",
    "\n",
    "for loss_idx, loss_function_name in enumerate(loss_function_names):\n",
    "    cnn = CNN(num_classes=num_classes).to(device)\n",
    "    optimizer = optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "    criterion = None\n",
    "\n",
    "    if loss_function_name == \"Ensemble Loss\":\n",
    "        criterion = ensemble_criterion\n",
    "    elif loss_function_name == \"MSE Loss\":\n",
    "        criterion = mse_criterion\n",
    "    elif loss_function_name == \"MAE Loss\":\n",
    "        criterion = mae_criterion\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        cnn.train()  # Set the model to training mode\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Convert labels to one-hot encoding\n",
    "            labels_one_hot = nn.functional.one_hot(labels, num_classes=num_classes).float()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = cnn(images)\n",
    "            loss = criterion(outputs, labels_one_hot)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track the losses\n",
    "            loss_lists[loss_idx].append(loss.item())\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                correct = (predicted == labels).sum().item()\n",
    "                accuracy = correct / labels.size(0)\n",
    "                accuracy_lists[loss_idx].append(accuracy)\n",
    "\n",
    "                print(f\"Loss Function: {loss_function_name}, Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{total_step}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Test with the current loss function\n",
    "    cnn.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = cnn(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_accuracy = correct / total\n",
    "        print(f\"Accuracy on the test set with {loss_function_name}: {test_accuracy:.4f}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Loss comparison plot\n",
    "plt.subplot(1, 2, 1)\n",
    "for loss_idx, loss_function_name in enumerate(loss_function_names):\n",
    "    plt.plot(loss_lists[loss_idx], label=loss_function_name)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy comparison plot\n",
    "plt.subplot(1, 2, 2)\n",
    "for loss_idx, loss_function_name in enumerate(loss_function_names):\n",
    "    plt.plot(accuracy_lists[loss_idx], label=loss_function_name)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d45adb",
   "metadata": {},
   "source": [
    "## Comparison of Different Loss Functions for CIFAR-10 Classification\n",
    "\n",
    "In this experiment, we trained a Convolutional Neural Network (CNN) for the CIFAR-10 classification task using three different loss functions: Ensemble Loss, Mean Squared Error (MSE) Loss, and Mean Absolute Error (MAE) Loss. The goal was to compare their performances on the test set and understand how each loss function impacts the model's accuracy and convergence.\n",
    "\n",
    "### Loss Functions Used:\n",
    "\n",
    "1. **Ensemble Loss:** A custom loss function that combines MSE and MAE losses. It aims to find a balance between the two error metrics, providing a flexible approach to training the model.\n",
    "\n",
    "2. **MSE Loss:** The traditional Mean Squared Error loss function, measuring the average squared difference between predicted probabilities and one-hot encoded target labels.\n",
    "\n",
    "3. **MAE Loss:** The Mean Absolute Error loss function, measuring the average absolute difference between predicted probabilities and one-hot encoded target labels.\n",
    "\n",
    "### Comparison Results:\n",
    "\n",
    "1. **MSE Loss:** Achieved the highest accuracy on the test set, demonstrating the best overall performance for this classification task. The sensitivity to large errors due to the squared term provided a strong signal for the model to adjust its parameters effectively.\n",
    "\n",
    "2. **Ensemble Loss:** Performed second-best among the three loss functions. While it didn't outperform MSE loss, it offered a balanced compromise between MSE and MAE, taking into account both squared and absolute errors.\n",
    "\n",
    "3. **MAE Loss:** Achieved the lowest accuracy among the three. The MAE loss function's reduced sensitivity to large errors might lead to slower convergence or less optimal parameter adjustments.\n",
    "\n",
    "It's essential to note that the choice of the most suitable loss function can depend on the dataset, model architecture, and specific task. In this experiment, MSE loss demonstrated superior performance, but it's always beneficial to experiment with different loss functions and hyperparameters to find the optimal combination for a given problem. Additionally, using an ensemble loss that combines various loss functions can provide greater flexibility and adaptability to different use cases, allowing fine-tuning of the model's behavior as per specific requirements.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edge",
   "language": "python",
   "name": "edge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
